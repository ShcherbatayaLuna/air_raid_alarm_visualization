{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          –î–∞—Ç–∞ —Ç–∞ —á–∞—Å                                              –ú—ñ—Å—Ü–µ  \\\n",
      "0 2022-04-10 00:04:39                                 –•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å   \n",
      "1 2022-04-10 00:46:59                                 –•–∞—Ä–∫—ñ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å   \n",
      "2 2022-04-10 01:05:47                           –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å   \n",
      "3 2022-04-10 01:06:24  –º. –ö—Ä–∏–≤–∏–π –†—ñ–≥ —Ç–∞ –ö—Ä–∏–≤–æ—Ä—ñ–∑—å–∫–∞ —Ç–µ—Ä–∏—Ç–æ—Ä—ñ–∞–ª—å–Ω–∞ –≥—Ä–æ...   \n",
      "4 2022-04-10 01:29:23                           –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å   \n",
      "\n",
      "    –¢–∏–ø –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è  \n",
      "0     –í—ñ–¥–±—ñ–π —Ç—Ä–∏–≤–æ–≥–∏  \n",
      "1  –ü–æ–≤—ñ—Ç—Ä—è–Ω–∞ —Ç—Ä–∏–≤–æ–≥–∞  \n",
      "2  –ü–æ–≤—ñ—Ç—Ä—è–Ω–∞ —Ç—Ä–∏–≤–æ–≥–∞  \n",
      "3  –ü–æ–≤—ñ—Ç—Ä—è–Ω–∞ —Ç—Ä–∏–≤–æ–≥–∞  \n",
      "4     –í—ñ–¥–±—ñ–π —Ç—Ä–∏–≤–æ–≥–∏  \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # –°–ø–∏—Å–æ–∫ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö\n",
    "    processed_data = []\n",
    "    \n",
    "    for message in data.get('messages', []):\n",
    "        if message['type'] == 'message':\n",
    "            try:\n",
    "                # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞—Ç—É —Ç–∞ —á–∞—Å\n",
    "                message_date = datetime.fromisoformat(message['date'])\n",
    "                \n",
    "                # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è\n",
    "                message_text = ' '.join([item['text'] if isinstance(item, dict) and 'text' in item else item for item in message['text']])\n",
    "\n",
    "                # –®—É–∫–∞—î–º–æ —Ö–µ—à—Ç–µ–≥–∏, —â–æ–± –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –º—ñ—Å—Ü–µ\n",
    "                hashtag_matches = re.findall(r\"#([–ê-–Ø–∞-—è–Ü—ñ–á—ó–Ñ—î“ê“ë0-9_]*)\", message_text)\n",
    "                if hashtag_matches:\n",
    "                    # –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ–≥–æ —Ö–µ—à—Ç–µ–≥—É –∑–∞–º—ñ–Ω—é—î–º–æ –Ω–∏–∂–Ω—î –ø—ñ–¥–∫—Ä–µ—Å–ª–µ–Ω–Ω—è –Ω–∞ –ø—Ä–æ–±—ñ–ª —ñ –≤–∏–¥–∞–ª—è—î–º–æ —Å–∞–º —Å–∏–º–≤–æ–ª \"#\"\n",
    "                    place = ' '.join([match.replace(\"_\", \" \") for match in hashtag_matches])\n",
    "                else:\n",
    "                    place = None\n",
    "                \n",
    "                # –î–æ–¥–∞—î–º–æ —Ç–æ—á–∫—É –ø—ñ—Å–ª—è \"–º\", —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î (—Å–∫–æ—Ä–æ—á–µ–Ω–Ω—è –¥–ª—è \"–º—ñ—Å—Ç–æ\")\n",
    "                if place and place.startswith(\"–º \") and not place.startswith(\"–º. \"):\n",
    "                    place = \"–º. \" + place[2:]\n",
    "\n",
    "                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç–∏–ø –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è (–ü–æ–≤—ñ—Ç—Ä—è–Ω–∞ —Ç—Ä–∏–≤–æ–≥–∞ –∞–±–æ –í—ñ–¥–±—ñ–π —Ç—Ä–∏–≤–æ–≥–∏)\n",
    "                message_type = \"–ü–æ–≤—ñ—Ç—Ä—è–Ω–∞ —Ç—Ä–∏–≤–æ–≥–∞\" if \"üî¥\" in message_text else \"–í—ñ–¥–±—ñ–π —Ç—Ä–∏–≤–æ–≥–∏\"\n",
    "\n",
    "                # –î–æ–¥–∞—î–º–æ —Ä—è–¥–æ–∫ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "                processed_data.append({\n",
    "                    '–î–∞—Ç–∞ —Ç–∞ —á–∞—Å': message_date,\n",
    "                    '–ú—ñ—Å—Ü–µ': place,\n",
    "                    '–¢–∏–ø –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è': message_type\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {e}\")\n",
    "                \n",
    "    return processed_data\n",
    "\n",
    "def process_multiple_json_files(directory_path):\n",
    "    # –®—É–∫–∞—î–º–æ –≤—Å—ñ JSON —Ñ–∞–π–ª–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó\n",
    "    file_paths = glob.glob(f\"{directory_path}/*.json\")\n",
    "    \n",
    "    all_data = []\n",
    "    for file_path in file_paths:\n",
    "        all_data.extend(process_json_file(file_path))\n",
    "    \n",
    "    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ —É—Å—ñ—î—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# –í–∫–∞–∑—É—î–º–æ —à–ª—è—Ö –¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ JSON —Ñ–∞–π–ª–∞–º–∏\n",
    "directory_path = './archive'\n",
    "\n",
    "# –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—ñ–≤\n",
    "final_df = process_multiple_json_files(directory_path)\n",
    "\n",
    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –≤ CSV\n",
    "final_df.to_csv('processed_data.csv', index=False)\n",
    "\n",
    "# –í–∏–≤–µ—Å—Ç–∏ –ø–µ—Ä—à—ñ –∫—ñ–ª—å–∫–∞ —Ä—è–¥–∫—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏\n",
    "print(final_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
